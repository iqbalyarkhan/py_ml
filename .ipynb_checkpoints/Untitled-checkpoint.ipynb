{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ng Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a training set is fed to a learning algorithm, it generates an output function called <b> hypothesis </b> denoted by $h$. The job of hypothesis function is to take input, say the size of a house, and output its price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, $h$ maps from $x$ to $y$ where $x$ is the independent variable (size of the house) and $y$ is the dependent variable (price of the house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to represent the hypothesis $h$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_{\\theta}(x)$ = ${\\theta}_0 + {\\theta}_1.x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that $y$ or $h_{\\theta}(x)$ is a linear function. This is called <b> Univariate Linear Regression </b> (or single variable linear regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Linear Regression and Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>m</b>: Number of training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this equation: $h_{\\theta}(x)$ = ${\\theta}_0 + {\\theta}_1.x$, the ${\\theta}_is$ are called <b>parameters</b> of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\theta}_0$ and ${\\theta}_1$ help determine what the cost function would look like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say for example if ${\\theta}_0$ = 1.5 and ${\\theta}_1$ = 0, we'll get a straight horizontal line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the idea is to get the most accurate ${\\theta}_0$ and ${\\theta}_1$ values so as to minimize the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to choose ${\\theta}_0$ and ${\\theta}_1$ so that $h_{\\theta}(x)$ is close to $y$ for our training examples $(x,y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want $$ J({\\theta_0,\\theta_1}) = \\frac{1}{2m} \\sum _{i=1}^m \\left(h_\\theta(X^{(i)})-Y^{(i)}\\right)^2$$ (difference between the output of my hypothesis and the actual price of the house squared) to be as small as possible. $m$ here is the number of training examples. Multiplying it by half to make math easier and the $m$ is present to get average over all the training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $J({\\theta_0,\\theta_1})$ is the <b> squared error cost function </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to minimize this cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with cost function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say our cost function is like so where ${\\theta}_0 = 0$ and ${\\theta}_1$ is the slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_{\\theta}(x) = {\\theta}_1.x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are two key functions we're intersted in:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(a)$ The hypothesis function $h_{\\theta}(x)$ (which is a function of $x$ which is the size of the house) and\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$ The cost function $J({\\theta_1})$ (which controls the slope of our line through the points) is a function of our parameter ${\\theta_1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $h_{\\theta}(x)$ will go through points $(1,1) (2,2) (3,3)$ and so on if I choose ${\\theta_1}$ as $1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what will the value of $J({\\theta_1})$ (the cost function) be, if ${\\theta_1} = 1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, our cost function was: $$ J({\\theta_0,\\theta_1}) = \\frac{1}{2m} \\sum _{i=1}^m \\left(h_\\theta(X^{(i)})-Y^{(i)}\\right)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where in our case ${\\theta_0}$ will be $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, since our ${\\theta_1} = 1$, the value inside parenthesis will be 0 (since, predicted value = exact value), therefore, cost function = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, $J(1) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each value of ${\\theta_1}$, these were the values of $J({\\theta_1})$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>${\\theta_1} = 1$ , $J({\\theta_1}) = 0$ </li>\n",
    "<li> ${\\theta_1} = 0.5$ , $J({\\theta_1}) = 0.583$</li>\n",
    "<li> ${\\theta_1} = 0$ , $J({\\theta_1}) = 2.3$</li>\n",
    "<li> ${\\theta_1} = -0.5$ , $J({\\theta_1}) = 5.25$</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want to choose the value of ${\\theta_1}$ that minimizes $J({\\theta_1})$, which is the first set in the list above: ${\\theta_1} = 1$ , $J({\\theta_1}) = 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with cost function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous example was for a cost function where ${\\theta}_0 = 0$ and ${\\theta}_1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have have a cost function where both thetas are non-zero, we get a cost function that is bowl shaped. It is also 3D. AKA contour plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Gradient Descent </b> is used to minimize the cost function. The ideas is that we start with some ${\\theta}_0$ and ${\\theta}_1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to a person going toward the lowest point in the valley by taking small steps to points that'll take you down the fastest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent formula: ${\\theta}_j := {\\theta}_j - {\\alpha}\\frac{\\partial}{\\partial {\\theta}_j}J({\\theta_0,\\theta_1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few things to note here:\n",
    "<li> ${\\alpha}$ is the learning rate ie how fast you want to descend </li>\n",
    "<li> $\\frac{\\partial}{\\partial {\\theta}_j}J({\\theta_0,\\theta_1})$ is the derivative that tells you which direction to move in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal equation: $\\hat\\theta=(X^TX)^{-1}X^Ty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inserting $x_0$ as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserting $x_0$ as 1\n",
    "X = np.c_[np.ones((100,1)), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transposed = X.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_transposed.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linalg.inv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat = X.dot(X_transposed).dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As the equation below shows, the normal equation found our ${\\theta_0}$ and ${\\theta_1}$ to be: 8.02 and 2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_theta(x) = [7.83450398] + [2.13115028]x per normal equation\n"
     ]
    }
   ],
   "source": [
    "print(\"h_theta(x) = {0} + {1}x per normal equation\".format(theta_hat[0], theta_hat[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding ${\\theta_0}$ and ${\\theta_1}$ using gradient descent and normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_data():\n",
    "    X = 2 * np.random.rand(100,1)\n",
    "    y = 8 + 2 * X + np.random.randn(100,1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X,y):\n",
    "    # adding x0 = 1\n",
    "    X = np.c_[np.ones((100,1)), X]\n",
    "    X_transposed = X.transpose()\n",
    "    # print(\"shape of X is: {0}\".format(X.shape))\n",
    "    # print(\"shape of X` is: {0}\".format(X_transposed.shape))\n",
    "    X = X_transposed.dot(X)\n",
    "    X = np.linalg.inv(X)\n",
    "    theta_hat = X.dot(X_transposed).dot(y)\n",
    "    # print(\"Shape of y is: {0}\".format(y.shape))\n",
    "    # print(\"Actual values of y are: {0}\".format(y))\n",
    "    return theta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,y):\n",
    "    alpha = 0.1\n",
    "    iterations = 1000\n",
    "    m = 100\n",
    "    theta = np.random.randn(2,1)\n",
    "    X = np.c_[np.ones((100, 1)), X]\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        X_transposed = X.transpose()\n",
    "        val = X_transposed.dot(X.dot(theta) - y)\n",
    "        theta = theta - (alpha/m)*(val)\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = create_data()\n",
    "plt.plot(X,y,\"rx\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat = normal_equation(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_theta(x) = [8.24707546] + [1.8006338]x per normal equation\n"
     ]
    }
   ],
   "source": [
    "print(\"h_theta(x) = {0} + {1}x per normal equation\".format(theta_hat[0], theta_hat[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_gd = gradient_descent(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_gd is: [[8.24707529]\n",
      " [1.80063394]]\n"
     ]
    }
   ],
   "source": [
    "print(\"theta_gd is: {0}\".format(theta_gd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
